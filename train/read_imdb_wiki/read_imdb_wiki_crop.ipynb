{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following notebook reads .mat files of imdb_crop and wiki_crop and prepares metadata.csv file with a list of not-corrupted pictures with parsed age and gender information. Please, download corresponding data to the data folder or provide a path to data in /data/consts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of crop faces:  224607\n",
      "File is saved to  D:\\WUT\\IML\\data/metadata-clean.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "train_module_path = os.path.abspath(os.path.join('..'))\n",
    "if train_module_path not in sys.path:\n",
    "    sys.path.append(train_module_path)\n",
    "\n",
    "from data.consts import DATA_DIR\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import datetime as date\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "cols = ['age', 'gender', 'path', 'face_score1', 'face_score2']\n",
    "\n",
    "IMDB = 'imdb'\n",
    "WIKI = 'wiki'\n",
    "datasets = [IMDB, WIKI]\n",
    "\n",
    "def extract_birthdate(images_path, dataset):\n",
    "    dob = []\n",
    "    if dataset == IMDB:\n",
    "        for file in images_path:\n",
    "            temp = file.split('_')[3]\n",
    "            temp = temp.split('-')\n",
    "            if len(temp[1]) == 1:\n",
    "                temp[1] = '0' + temp[1]\n",
    "            if len(temp[2]) == 1:\n",
    "                temp[2] = '0' + temp[2]\n",
    "\n",
    "            if temp[1] == '00':\n",
    "                temp[1] = '01'\n",
    "            if temp[2] == '00':\n",
    "                temp[2] = '01'        \n",
    "            dob.append('-'.join(temp))\n",
    "    elif dataset == WIKI:\n",
    "        for file in images_path:\n",
    "            dob.append(file.split('_')[2])\n",
    "    return dob\n",
    "\n",
    "def extract_images_path(crop_path, full_paths):\n",
    "    images_path = []\n",
    "    for path in full_paths:\n",
    "        images_path.append(crop_path + '/' + path[0])\n",
    "    return images_path\n",
    "\n",
    "def extract_genders(gender):\n",
    "    genders = []\n",
    "    for n in range(len(gender)):\n",
    "        if gender[n] == 1:\n",
    "            genders.append('male')\n",
    "        else:\n",
    "            genders.append('female')\n",
    "    return genders\n",
    "\n",
    "def extract_ages(dob, photo_taken):\n",
    "    age = []\n",
    "    for i in range(len(dob)):\n",
    "        try:\n",
    "            d1 = date.datetime.strptime(dob[i][0:10], '%Y-%m-%d')\n",
    "            d2 = date.datetime.strptime(str(photo_taken[i]), '%Y')\n",
    "            rdelta = relativedelta(d2, d1)\n",
    "            diff = rdelta.years\n",
    "        except Exception as ex:\n",
    "            diff = -1\n",
    "        age.append(diff)\n",
    "    return age\n",
    "\n",
    "def prepare_dataframe(dataset):\n",
    "    crop_path = DATA_DIR + '/' + dataset + '_crop'\n",
    "    dataset_mat = crop_path + '/' + dataset + '.mat'\n",
    "    dataset_data = loadmat(dataset_mat)\n",
    "\n",
    "    photo_taken = dataset_data[dataset][0][0][1][0]\n",
    "    full_paths = dataset_data[dataset][0][0][2][0]\n",
    "    gender = dataset_data[dataset][0][0][3][0]\n",
    "    face_score1 = dataset_data[dataset][0][0][6][0]\n",
    "    face_score2 = dataset_data[dataset][0][0][7][0]\n",
    "\n",
    "    images_path = extract_images_path(crop_path, full_paths)\n",
    "    genders = extract_genders(gender)\n",
    "    dob = extract_birthdate(images_path, dataset)\n",
    "    age = extract_ages(dob, photo_taken)\n",
    "\n",
    "    final = np.vstack((age, genders, images_path, face_score1, face_score2)).T\n",
    "    final_df = pd.DataFrame(final)\n",
    "    final_df.columns = cols\n",
    "    return final_df\n",
    "\n",
    "\n",
    "meta = pd.concat((prepare_dataframe(IMDB), prepare_dataframe(WIKI)))\n",
    "\n",
    "# Clean up corrupted pictures\n",
    "meta = meta[meta['face_score1'] != '-inf']\n",
    "meta = meta[meta['face_score2'] == 'nan']\n",
    "\n",
    "meta = meta.drop(['face_score2'], axis=1)\n",
    "\n",
    "meta.to_csv(DATA_DIR + '/metadata.csv', index=False)\n",
    "\n",
    "# Data clean up based on EDA\n",
    "meta['age'] = pd.to_numeric(meta['age'])\n",
    "meta = meta[meta['age'] > -1]\n",
    "meta = meta[meta['age'] < 123]\n",
    "meta.to_csv(DATA_DIR + '/metadata-clean.csv', index=False)\n",
    "\n",
    "\n",
    "print('Amount of crop faces: ', len(meta))\n",
    "print('File is saved to ', DATA_DIR + '/metadata-clean.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
